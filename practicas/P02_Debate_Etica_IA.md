# P02 - Debate y ensayo: √âtica en sistemas automatizados

## üìã Informaci√≥n general

- **Unidad**: U2 - √âtica, sesgos y legislaci√≥n en IA
- **Bloque**: B1 - Introducci√≥n a la IA
- **Modalidad**: Grupal (3-4 estudiantes) 
- **Duraci√≥n**: 1 hora
- **Entrega**: Debate grupal

## üéØ Objetivos

Al completar esta pr√°ctica, el estudiante ser√° capaz de:

- **Analizar** casos reales de sesgos algor√≠tmicos y sus consecuencias
- **Argumentar** posiciones √©ticas de forma fundamentada y estructurada
- **Evaluar** dilemas morales en el desarrollo de sistemas automatizados
- **Reflexionar** cr√≠ticamente sobre la responsabilidad en IA
- **Proponer** soluciones pr√°cticas para problemas √©ticos identificados

## üìö Descripci√≥n de la pr√°ctica

### Debate grupal 

#### Formato del debate
- **Modalidad**: Debate acad√©mico estructurado
- **Duraci√≥n**: 25 minutos por grupo
- **Estructura**: Oxford-style debate
- **Participantes**: 2 equipos de 3-4 estudiantes cada uno

#### Temas de debate disponibles

**Tema 1: "Deber√≠amos priorizar la equidad algor√≠tmica aunque reduzca la precisi√≥n del sistema"**

*Contexto: Un algoritmo de contrataci√≥n con 95% de precisi√≥n tiene sesgo de g√©nero. Corregirlo reduce la precisi√≥n al 87% pero elimina el sesgo.*

- **Posici√≥n A**: La equidad es un imperativo √©tico que justifica sacrificar precisi√≥n. Un sistema justo al 87% es mejor que uno preciso pero discriminatorio al 95%.
- **Posici√≥n B**: La precisi√≥n maximiza beneficios generales. Reducir precisi√≥n perjudica a todos (incluidos grupos protegidos). Mejor corregir sesgos sin comprometer rendimiento.

**Dilema**: ¬øEquidad absoluta vs. beneficio general? ¬øCu√°nta precisi√≥n estamos dispuestos a perder por equidad?

---

**Tema 2: "Una IA debe poder mentir si salva vidas"**

*Contexto: Un chatbot de salud mental detecta que un usuario est√° considerando suicidio. ¬øPuede mentir sobre "enviar ayuda" para mantenerlo hablando hasta que llegue asistencia real?*

- **Posici√≥n A**: La preservaci√≥n de la vida humana es el valor supremo. Si mentir salva vidas, es √©ticamente justificable. El fin (salvar vida) justifica el medio (mentir).
- **Posici√≥n B**: La confianza en sistemas de IA es fundamental. Una vez que permitimos mentir "por buenas razones", abrimos la puerta a abusos. La transparencia no debe comprometerse nunca.

**Dilema**: ¬øConsecuencialismo vs. deontolog√≠a? ¬øQui√©n decide cu√°ndo est√° justificada la mentira?

---

**Tema 3: "Es aceptable usar datos sesgados hist√≥ricos si corregimos las predicciones despu√©s"**

*Contexto: Tenemos 50 a√±os de datos de pr√©stamos bancarios con discriminaci√≥n racial hist√≥rica. Podemos: (A) Usar todos los datos y corregir sesgos despu√©s, o (B) Eliminar datos sesgados pero tener menos datos para entrenar.*

- **Posici√≥n A**: Aprovechar toda la informaci√≥n disponible y corregir matem√°ticamente es m√°s efectivo. Los datos hist√≥ricos contienen patrones valiosos m√°s all√° del sesgo. Post-procesamiento es suficiente.
- **Posici√≥n B**: "Garbage in, garbage out". Los sesgos se propagan de formas invisibles. Es mejor tener menos datos limpios que muchos datos corruptos. Pre-procesamiento es insuficiente.

**Dilema**: ¬øPodemos realmente "limpiar" sesgos hist√≥ricos? ¬øCantidad de datos vs. calidad √©tica?

---

**Tema 4: "Los desarrolladores de IA tienen mayor responsabilidad √©tica que los usuarios"**

*Contexto: Un usuario usa ChatGPT para escribir fake news que causan da√±o. ¬øQui√©n es m√°s responsable: OpenAI (creador) o el usuario (ejecutor)?*

- **Posici√≥n A**: Los desarrolladores crean herramientas potencialmente peligrosas y deben anticipar abusos. Tienen conocimiento t√©cnico y poder para prevenir. Responsabilidad del creador es mayor (como fabricante de armas).
- **Posici√≥n B**: Los usuarios tienen agencia y libre albedr√≠o. Culpar a desarrolladores es como culpar a fabricantes de cuchillos por asesinatos. La responsabilidad principal recae en quien ejecuta la acci√≥n da√±ina.

**Dilema**: ¬øD√≥nde termina la responsabilidad del creador? ¬øHasta qu√© punto debemos limitar herramientas por potencial abuso?

---

**Tema 5: "Es √©tico usar IA para predecir cr√≠menes antes de que ocurran"**

*Contexto: Un sistema de IA predice con 70% de precisi√≥n qui√©n cometer√° un crimen en los pr√≥ximos 6 meses bas√°ndose en datos socioecon√≥micos, historial y comportamiento. ¬øUsamos esta informaci√≥n?*

- **Posici√≥n A**: Si podemos prevenir cr√≠menes y salvar v√≠ctimas potenciales, tenemos obligaci√≥n moral de hacerlo. La predicci√≥n permite intervenci√≥n preventiva (trabajo social, terapia) que beneficia a todos.
- **Posici√≥n B**: Esto es castigar/estigmatizar a personas por cr√≠menes no cometidos. 30% de falsos positivos arruinar√° vidas inocentes. Viola presunci√≥n de inocencia y reproduce sesgos estructurales.

**Dilema**: ¬øPrevenci√≥n vs. presunci√≥n de inocencia? ¬øCu√°nta precisi√≥n necesitamos para justificar acci√≥n predictiva?

---

#### Estructura del debate

**1. Preparaci√≥n (15 minutos antes del debate)**
- Revisi√≥n final de argumentos
- Distribuci√≥n de roles (moderador, cronometrador, etc.)
- Configuraci√≥n t√©cnica

**2. Apertura (8 minutos)**
- **Presentaci√≥n del tema** (moderador): 2 minutos
- **Discurso de apertura Equipo A**: 3 minutos
  - Exponer tesis principal y argumentos clave
- **Discurso de apertura Equipo B**: 3 minutos
  - Exponer contra-tesis y argumentos principales

**3. Argumentaci√≥n y refutaci√≥n (25 minutos)**
- **Primer orador Equipo A**: 3 minutos
  - Desarrollar primer argumento principal
- **Primer orador Equipo B - REFUTA**: 3 minutos
  - Contra-argumentar el punto anterior Y presentar argumento propio
- **Segundo orador Equipo A - REFUTA**: 3 minutos
  - Defender posici√≥n inicial Y refutar argumento del Equipo B
- **Segundo orador Equipo B - REFUTA**: 3 minutos
  - Continuar refutaci√≥n Y desarrollar nuevo argumento
- **Tercer orador Equipo A - REFUTA**: 3 minutos
  - Reforzar argumentos Y contra-atacar puntos d√©biles detectados
- **Tercer orador Equipo B - REFUTA**: 3 minutos
  - Responder refutaciones Y consolidar posici√≥n
- **Ronda libre de contra-argumentaci√≥n**: 7 minutos
  - **Formato**: Intercambio r√°pido y directo entre equipos
  - **Mec√°nica**: 
    - Turnos de 1 minuto alternados entre equipos
    - Cualquier miembro del equipo puede intervenir
    - El moderador da la palabra levantando la mano
  - **Objetivo**: 
    - Atacar puntos d√©biles espec√≠ficos del equipo contrario
    - Responder ataques directos
    - Clarificar malentendidos o tergiversaciones
    - Forzar al equipo contrario a defender inconsistencias

**4. Res√∫menes finales (8 minutos)**
- **Resumen final Equipo B**: 4 minutos
  - Sintetizar argumentos principales, refutar ataques clave, conclusi√≥n fuerte
- **Resumen final Equipo A**: 4 minutos
  - Sintetizar posici√≥n, responder √∫ltimas refutaciones, llamado final

**5. Preguntas y cierre (4 minutos)**
- **Preguntas de la audiencia**: 3 minutos
- **Comentarios finales del moderador**: 1 minuto

**5. Evaluaci√≥n (5 minutos)**
- Votaci√≥n de la audiencia (no vinculante)
- Feedback del profesor
- Autoevaluaci√≥n grupal

#### Criterios de evaluaci√≥n del debate

**Contenido y argumentaci√≥n (40%)**
- Solidez de argumentos respaldados por evidencia
- Uso apropiado de ejemplos y casos reales
- Demostraci√≥n de conocimiento del tema

**Refutaci√≥n y contra-argumentaci√≥n (30%)**
- Capacidad de responder a argumentos opuestos
- Identificaci√≥n de falacias l√≥gicas
- Construcci√≥n de contra-argumentos s√≥lidos

**Comunicaci√≥n y presentaci√≥n (20%)**
- Claridad en la exposici√≥n
- Uso efectivo del tiempo asignado
- Lenguaje apropiado y profesional

**Trabajo en equipo (10%)**
- Coordinaci√≥n entre miembros del equipo
- Distribuci√≥n equitativa de participaci√≥n
- Apoyo mutuo durante el debate


## üîç Preparaci√≥n para el debate

### Investigaci√≥n requerida

**Cada equipo debe preparar:**
- **Argumentos principales** (m√≠nimo 5) con evidencia s√≥lida
- **Contra-argumentos anticipados** para refutar posiciones opuestas
- **Casos de estudio** reales que apoyen su posici√≥n
- **Datos estad√≠sticos** y estudios acad√©micos relevantes
- **Propuestas concretas** de implementaci√≥n o regulaci√≥n

### Recursos de investigaci√≥n

**Fuentes acad√©micas:**
- Partnership on AI - Tenets
- AI Ethics Guidelines Global Inventory (AlgorithmWatch)
- IEEE Standards for Ethical AI Design
- MIT Technology Review - AI Ethics articles

**Casos de estudio:**
- Amazon recruitment algorithm bias (2018)
- Facebook emotional contagion experiment (2014)
- Google Photos racial classification error (2015)
- Microsoft Tay chatbot incident (2016)

**Legislaci√≥n y regulaci√≥n:**
- EU AI Act (2024)
- GDPR Articles 22 (automated decisions)
- California Consumer Privacy Act (CCPA)
- UNESCO AI Ethics Recommendation

### Estrategias de argumentaci√≥n

**Estructura de argumentos s√≥lidos:**
1. **Premisa**: Afirmaci√≥n clara y espec√≠fica
2. **Evidencia**: Datos, estudios o ejemplos que la apoyan
3. **Justificaci√≥n**: Explicaci√≥n de por qu√© la evidencia apoya la premisa
4. **Implicaciones**: Consecuencias de aceptar o rechazar el argumento

**T√©cnicas de refutaci√≥n:**
- **Cuestionar la evidencia**: ¬øEs relevante, actualizada, suficiente?
- **Identificar falacias l√≥gicas**: Ad hominem, straw man, false dichotomy
- **Ofrecer evidencia contraria**: Datos que contradicen la posici√≥n opuesta
- **Mostrar consecuencias no deseadas**: Efectos negativos de la propuesta rival

## üéì Evaluaci√≥n detallada

### R√∫brica del debate grupal

| Criterio | Excelente (4) | Bueno (3) | Satisfactorio (2) | Insuficiente (1) |
|----------|---------------|-----------|-------------------|------------------|
| **Argumentaci√≥n** | Argumentos s√≥lidos, bien estructurados y respaldados por evidencia convincente | Argumentos claros con evidencia adecuada | Argumentos b√°sicos con evidencia limitada | Argumentos d√©biles o sin evidencia |
| **Conocimiento** | Demuestra comprensi√≥n profunda del tema y contexto | Muestra buen conocimiento con algunos gaps menores | Conocimiento b√°sico suficiente | Conocimiento superficial o incorrecto |
| **Refutaci√≥n** | Refuta efectivamente argumentos opuestos con contra-evidencia s√≥lida | Buenas refutaciones con argumentos v√°lidos | Refutaciones b√°sicas pero apropiadas | Refutaciones d√©biles o inexistentes |
| **Comunicaci√≥n** | Presentaci√≥n clara, persuasiva y bien organizada | Comunicaci√≥n efectiva con estructura clara | Comunicaci√≥n aceptable, ocasionalmente confusa | Comunicaci√≥n pobre o desorganizada |
| **Trabajo en equipo** | Excelente coordinaci√≥n y apoyo mutuo | Buena coordinaci√≥n con participaci√≥n equilibrada | Coordinaci√≥n b√°sica, algunas descompensaciones | Pobre coordinaci√≥n o participaci√≥n desigual |

## üí° Consejos para el √©xito

### Para el debate grupal
- **Practica en voz alta**: Ensaya argumentos con tu equipo
- **Anticipa contra-argumentos**: Prepara respuestas para objeciones probables
- **Usa casos reales**: Los ejemplos concretos son m√°s persuasivos
- **Mant√©n la calma**: Responde a ataques con profesionalismo
- **Gestiona el tiempo**: Distribuye el tiempo equitativamente entre puntos
## üîó Recursos adicionales

### Materiales de apoyo
- **Gu√≠a de debate acad√©mico**: T√©cnicas y estrategias
- **Checklist de argumentaci√≥n**: Para verificar solidez l√≥gica
- **Ejemplos de ensayos √©ticos**: Modelos de estructura y argumentaci√≥n
- **Base de datos de casos**: Repositorio de casos de estudio actualizados

### Herramientas recomendadas
- **Argument mapping software**: Lucidchart, MindMeister
- **Citation managers**: Zotero, Mendeley
- **Collaborative platforms**: Google Docs, Notion
- **Timer apps**: Para practicar gesti√≥n de tiempo en debates

## üìã Entregables

### Debate grupal
- **Documento de preparaci√≥n** (compartido): Argumentos principales, evidencia y fuentes
- **Participaci√≥n activa**: En el debate asignado y como audiencia en otros debates

## ‚ùì Preguntas frecuentes

**P: ¬øPuedo cambiar de equipo una vez asignado?**
R: Solo en circunstancias excepcionales y con aprobaci√≥n del profesor.

**P: ¬øQu√© pasa si mi equipo no puede participar en el debate por enfermedad?**
R: Se reprogramar√° para la siguiente sesi√≥n. En caso extremo, se evaluar√° con presentaci√≥n grabada.

**P: ¬øHay penalizaci√≥n por defender una posici√≥n con la que no estoy de acuerdo?**
R: No. El objetivo es desarrollar habilidades argumentativas independientemente de creencias personales.

---

**Pr√°ctica elaborada por**: Departamento de Inform√°tica y Comunicaciones  
**√öltima actualizaci√≥n**: 26 de octubre de 2025